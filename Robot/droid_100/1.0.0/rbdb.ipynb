{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b04ca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import getpass as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc11825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 계정 정보 사전\n",
    "accounts = {\n",
    "    'root':   {'host': '127.0.0.1'},\n",
    "    'reader': {'host': '127.0.0.1'},\n",
    "    'writer': {'host': '127.0.0.1'},\n",
    "    'edward': {'host': '192.168.0.27'},\n",
    "    # 여기에 계정 추가 가능\n",
    "}\n",
    "\n",
    "def connect_to_db():\n",
    "    user = input(\"ID: \").strip()\n",
    "    if user not in accounts:\n",
    "        raise ValueError(\"등록되지 않은 사용자 ID\")\n",
    "\n",
    "    password = gp.getpass(\"비밀번호: \")\n",
    "    host = accounts[user]['host']\n",
    "\n",
    "    # DB 이름을 반드시 입력받도록\n",
    "    while True:\n",
    "        db_name = input(\"접속할 DB 이름을 입력하세요: \").strip()\n",
    "        if db_name:\n",
    "            break\n",
    "        print(\"DB 이름은 비어 있을 수 없습니다. 다시 입력해주세요.\")\n",
    "\n",
    "    conn = pymysql.connect(\n",
    "        host=host,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        db=db_name,\n",
    "        charset='utf8mb4'\n",
    "    )\n",
    "    return conn\n",
    "\n",
    "def q(query):\n",
    "    with conn.cursor() as cursor: # 커서 생성 with 구문을 사용해서 자동으로 close 하므로 메모리 누수를 방지\n",
    "        cursor.execute(query)\n",
    "        first = query.strip().split()[0].lower()\n",
    "        if first in ['select', 'show', 'describe', 'desc', 'explain']:\n",
    "            df = pd.read_sql(query, conn)\n",
    "            display(df)\n",
    "        else:\n",
    "            conn.commit()\n",
    "            print(\"Query OK.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2893257a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = connect_to_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7415e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query OK.\n"
     ]
    }
   ],
   "source": [
    "q(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS dataset_versions (\n",
    "  dataset_name   VARCHAR(255) PRIMARY KEY,\n",
    "  version        VARCHAR(64) NOT NULL,\n",
    "  file_format    VARCHAR(64),\n",
    "  release_notes  TEXT\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "633e2cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query OK.\n",
      "Query OK.\n"
     ]
    }
   ],
   "source": [
    "q(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS splits (\n",
    "  split_id     INT AUTO_INCREMENT PRIMARY KEY,\n",
    "  dataset_name VARCHAR(255) NOT NULL,\n",
    "  split_name   VARCHAR(255) NOT NULL,\n",
    "  num_bytes    BIGINT,\n",
    "  num_shards   INT,\n",
    "  UNIQUE KEY ux_dataset_split (dataset_name, split_name),\n",
    "  FOREIGN KEY (dataset_name)\n",
    "    REFERENCES dataset_versions(dataset_name)\n",
    "      ON DELETE CASCADE\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\"\"\")\n",
    "q(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS shards (\n",
    "  shard_id     INT AUTO_INCREMENT PRIMARY KEY,\n",
    "  split_id     INT        NOT NULL,\n",
    "  shard_index  INT        NOT NULL,\n",
    "  num_examples INT        NOT NULL,\n",
    "  filepath     TEXT       NOT NULL,\n",
    "  UNIQUE KEY ux_split_shard (split_id, shard_index),\n",
    "  FOREIGN KEY (split_id)\n",
    "    REFERENCES splits(split_id)\n",
    "      ON DELETE CASCADE\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20b84a59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query OK.\n",
      "Query OK.\n"
     ]
    }
   ],
   "source": [
    "q(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS episodes (\n",
    "  episode_id      VARCHAR(255) PRIMARY KEY,\n",
    "  file_path       TEXT        NOT NULL,\n",
    "  recording_path  TEXT        NOT NULL\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\"\"\")\n",
    "q(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS steps (\n",
    "  step_id         BIGINT      PRIMARY KEY AUTO_INCREMENT,\n",
    "  episode_id      VARCHAR(255) NOT NULL,\n",
    "  step_index      INT         NOT NULL,\n",
    "  discount        FLOAT,\n",
    "  is_first        TINYINT(1),\n",
    "  is_last         TINYINT(1),\n",
    "  is_terminal     TINYINT(1),\n",
    "  reward          FLOAT,\n",
    "  lang_inst_1     TEXT,\n",
    "  lang_inst_2     TEXT,\n",
    "  lang_inst_3     TEXT,\n",
    "  action          JSON,\n",
    "  action_dict     JSON,\n",
    "  obs_cart_pos    JSON,\n",
    "  UNIQUE KEY ux_episode_step (episode_id, step_index),\n",
    "  FOREIGN KEY (episode_id)\n",
    "    REFERENCES episodes(episode_id)\n",
    "      ON DELETE CASCADE\n",
    ") ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5be2a695",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-12 22:26:29.138645: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-12 22:26:29.168090: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749734789.177732    7958 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749734789.180578    7958 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-12 22:26:29.211549: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import tensorflow as tf\n",
    "import pymysql\n",
    "from tensorflow.core.example import example_pb2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba77540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bytes(feature, key):\n",
    "    if key in feature and feature[key].bytes_list.value:\n",
    "        return feature[key].bytes_list.value[0].decode('utf-8')\n",
    "    return None\n",
    "\n",
    "def get_floats(feature, key):\n",
    "    return list(feature[key].float_list.value) if key in feature else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fbc1557",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step_idx, raw_record \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mds\u001b[49m):\n\u001b[1;32m      2\u001b[0m     ex \u001b[38;5;241m=\u001b[39m example_pb2\u001b[38;5;241m.\u001b[39mExample()\n\u001b[1;32m      3\u001b[0m     ex\u001b[38;5;241m.\u001b[39mParseFromString(raw_record\u001b[38;5;241m.\u001b[39mnumpy())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ds' is not defined"
     ]
    }
   ],
   "source": [
    "for step_idx, raw_record in enumerate(ds):\n",
    "    ex = example_pb2.Example()\n",
    "    ex.ParseFromString(raw_record.numpy())\n",
    "    f = ex.features.feature\n",
    "\n",
    "    # episode metadata\n",
    "    episode_id = get_bytes(f, \"episode_metadata/file_path\")\n",
    "    rec_path   = get_bytes(f, \"episode_metadata/recording_folderpath\")\n",
    "\n",
    "    if not episode_id or not rec_path:\n",
    "        print(f\"스킵 (episode_id 또는 rec_path 누락) at record {step_idx}\")\n",
    "        continue\n",
    "\n",
    "    # episodes 테이블에 저장\n",
    "    cur.execute(\n",
    "        \"INSERT IGNORE INTO episodes (episode_id, file_path, recording_path) VALUES (%s, %s, %s)\",\n",
    "        (episode_id, shard_fp, rec_path)\n",
    "    )\n",
    "\n",
    "    # 언어 지시문\n",
    "    li1 = get_bytes(f, \"steps/language_instruction\")\n",
    "    li2 = get_bytes(f, \"steps/language_instruction_2\")\n",
    "    li3 = get_bytes(f, \"steps/language_instruction_3\")\n",
    "\n",
    "    # 기본 스칼라 값들\n",
    "    discount = f[\"steps/discount\"].float_list.value[0]      if \"steps/discount\" in f      else None\n",
    "    is_first = int(f[\"steps/is_first\"].int64_list.value[0]) if \"steps/is_first\" in f     else 0\n",
    "    is_last  = int(f[\"steps/is_last\"].int64_list.value[0])  if \"steps/is_last\" in f      else 0\n",
    "    is_term  = int(f[\"steps/is_terminal\"].int64_list.value[0]) if \"steps/is_terminal\" in f else 0\n",
    "    reward   = f[\"steps/reward\"].float_list.value[0]        if \"steps/reward\" in f        else None\n",
    "\n",
    "    # 액션 벡터 (기존 `steps/action`)\n",
    "    action = json.dumps(get_floats(f, \"steps/action\"))\n",
    "\n",
    "    # action_dict 안의 여러 필드를 통째로 저장\n",
    "    action_dict = {}\n",
    "    for key in f:\n",
    "        if key.startswith(\"steps/action_dict/\"):\n",
    "            subkey = key.split(\"/\", 2)[-1]  # e.g. \"cartesian_position\"\n",
    "            action_dict[subkey] = get_floats(f, key)\n",
    "    action_dict_json = json.dumps(action_dict)\n",
    "\n",
    "    # 관절 위치 관찰값 중 cartesian_position 하나만 예시로\n",
    "    obs_cart = get_floats(f, \"steps/observation/cartesian_position\")\n",
    "    obs_cart_json = json.dumps(obs_cart)\n",
    "\n",
    "    # steps 테이블에 저장\n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO steps\n",
    "          (episode_id, step_index, discount, is_first, is_last, is_terminal,\n",
    "           reward, lang_inst_1, lang_inst_2, lang_inst_3,\n",
    "           action, action_dict, obs_cart_pos)\n",
    "        VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "        \"\"\",\n",
    "        (episode_id,\n",
    "         step_idx,\n",
    "         discount, is_first, is_last, is_term,\n",
    "         reward,\n",
    "         li1, li2, li3,\n",
    "         action, action_dict_json, obs_cart_json)\n",
    "    )\n",
    "\n",
    "conn.commit()\n",
    "print(\"✅ 모든 레코드 적재 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mysql",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
