{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Airline Review Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 라이브러브러리 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "# NLTK 금지어 가져오기\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수 초기화\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수\n",
    "\n",
    "# 금지어 확장 함수\n",
    "def set_stop_words(extended_list):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words.extend(extended_list)\n",
    "    return stop_words\n",
    "\n",
    "extended_list = ['from', 'subject', 're', 'edu', \n",
    "    'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', \n",
    "    'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', \n",
    "    'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', \n",
    "    'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', \n",
    "    'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come', 'app', 'non']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 전처리 함수\n",
    "def preprocess_text(text_data,get_lemma=True, tags=(), stop_words=[]):\n",
    "    # 소문자 변경\n",
    "    text_data = text_data.lower()\n",
    "    # URL 제거\n",
    "    text_data = re.sub(r'((www.\\S+)|(https?://\\S+))', r\"\", text_data)\n",
    "    # HTML 태그 제거\n",
    "    text_data = re.sub(r'<[^>]+>', r'', text_data)\n",
    "    # 숫자 제거\n",
    "    text_data = re.sub(r'[0-9]\\S+', r'', text_data)\n",
    "    # 문장부호 제거\n",
    "    text_data = [char for char in text_data if char not in string.punctuation]\n",
    "    text_data = \"\".join(text_data)\n",
    "    # 금지어 제거\n",
    "    text_data = [word for word in text_data.split() if word.lower() not in stop_words]\n",
    "    text_data = \" \".join(text_data)\n",
    "    # 래마타이즈\n",
    "    if get_lemma==True:\n",
    "        text_data = [lemmatizer.lemmatize(word) for word in text_data.split()]\n",
    "        text_data = \" \".join(text_data)\n",
    "    # POS 필터 \n",
    "    if len(tags)>0:\n",
    "        text_data = [word for word, pos in nltk.pos_tag(nltk.word_tokenize(text_data)) if pos.startswith(tags)]\n",
    "        text_data = \" \".join(text_data)\n",
    "\n",
    "    return text_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object sent_to_words at 0x0000014E0F481000>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent) \n",
    "        \n",
    "sent_to_words([\"sentences\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 데이터로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Clothing ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Recommended IND</th>\n",
       "      <th>Positive Feedback Count</th>\n",
       "      <th>Division Name</th>\n",
       "      <th>Department Name</th>\n",
       "      <th>Class Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>767</td>\n",
       "      <td>33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Absolutely wonderful - silky and sexy and comf...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Initmates</td>\n",
       "      <td>Intimate</td>\n",
       "      <td>Intimates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1080</td>\n",
       "      <td>34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Love this dress!  it's sooo pretty.  i happene...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1077</td>\n",
       "      <td>60</td>\n",
       "      <td>Some major design flaws</td>\n",
       "      <td>I had such high hopes for this dress and reall...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>General</td>\n",
       "      <td>Dresses</td>\n",
       "      <td>Dresses</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1049</td>\n",
       "      <td>50</td>\n",
       "      <td>My favorite buy!</td>\n",
       "      <td>I love, love, love this jumpsuit. it's fun, fl...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>General Petite</td>\n",
       "      <td>Bottoms</td>\n",
       "      <td>Pants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>847</td>\n",
       "      <td>47</td>\n",
       "      <td>Flattering shirt</td>\n",
       "      <td>This shirt is very flattering to all due to th...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>General</td>\n",
       "      <td>Tops</td>\n",
       "      <td>Blouses</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Clothing ID  Age                    Title  \\\n",
       "0           0          767   33                      NaN   \n",
       "1           1         1080   34                      NaN   \n",
       "2           2         1077   60  Some major design flaws   \n",
       "3           3         1049   50         My favorite buy!   \n",
       "4           4          847   47         Flattering shirt   \n",
       "\n",
       "                                         Review Text  Rating  Recommended IND  \\\n",
       "0  Absolutely wonderful - silky and sexy and comf...       4                1   \n",
       "1  Love this dress!  it's sooo pretty.  i happene...       5                1   \n",
       "2  I had such high hopes for this dress and reall...       3                0   \n",
       "3  I love, love, love this jumpsuit. it's fun, fl...       5                1   \n",
       "4  This shirt is very flattering to all due to th...       5                1   \n",
       "\n",
       "   Positive Feedback Count   Division Name Department Name Class Name  \n",
       "0                        0       Initmates        Intimate  Intimates  \n",
       "1                        4         General         Dresses    Dresses  \n",
       "2                        0         General         Dresses    Dresses  \n",
       "3                        0  General Petite         Bottoms      Pants  \n",
       "4                        6         General            Tops    Blouses  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터 가져오기\n",
    "file_name = \"./dataset/Womens Clothing E-Commerce Reviews.csv\"\n",
    "df = pd.read_csv(file_name )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23486, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23486 entries, 0 to 23485\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Unnamed: 0               23486 non-null  int64 \n",
      " 1   Clothing ID              23486 non-null  int64 \n",
      " 2   Age                      23486 non-null  int64 \n",
      " 3   Title                    19676 non-null  object\n",
      " 4   Review Text              22641 non-null  object\n",
      " 5   Rating                   23486 non-null  int64 \n",
      " 6   Recommended IND          23486 non-null  int64 \n",
      " 7   Positive Feedback Count  23486 non-null  int64 \n",
      " 8   Division Name            23472 non-null  object\n",
      " 9   Department Name          23472 non-null  object\n",
      " 10  Class Name               23472 non-null  object\n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결측 값 제거\n",
    "data = df.dropna(subset=[\"Review Text\"]).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 22641 entries, 0 to 23485\n",
      "Data columns (total 11 columns):\n",
      " #   Column                   Non-Null Count  Dtype \n",
      "---  ------                   --------------  ----- \n",
      " 0   Unnamed: 0               22641 non-null  int64 \n",
      " 1   Clothing ID              22641 non-null  int64 \n",
      " 2   Age                      22641 non-null  int64 \n",
      " 3   Title                    19675 non-null  object\n",
      " 4   Review Text              22641 non-null  object\n",
      " 5   Rating                   22641 non-null  int64 \n",
      " 6   Recommended IND          22641 non-null  int64 \n",
      " 7   Positive Feedback Count  22641 non-null  int64 \n",
      " 8   Division Name            22628 non-null  object\n",
      " 9   Department Name          22628 non-null  object\n",
      " 10  Class Name               22628 non-null  object\n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 텍스트 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = (\"JJ\", \"NN\", \"RB\", \"VB\")\n",
    "stop_words= set_stop_words(extended_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Review Text2'] = data.apply(lambda x: \n",
    "                                  preprocess_text(x['Review Text'], \n",
    "                                                  get_lemma=True, \n",
    "                                                  tags=TAGS,\n",
    "                                                  stop_words= stop_words), \n",
    "                                                  axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          absolutely wonderful silky sexy comfortable\n",
       "1    love dress sooo pretty happened find store im ...\n",
       "2    high hope dress really wanted work initially o...\n",
       "3    love love love jumpsuit fun flirty fabulous ti...\n",
       "4    shirt flattering due adjustable front tie perf...\n",
       "Name: Review Text2, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Review Text2'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. LDA 모델링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable']]\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "dataset = data['Review Text2'].values.tolist()\n",
    "data_words = list(sent_to_words(dataset))\n",
    "print(data_words[:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data['Review Text2'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['absolutely wonderful silky sexy comfortable']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_words = list(sent_to_words(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['absolutely', 'wonderful', 'silky', 'sexy', 'comfortable']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tracy_reese': 6151.303948576676,\n",
       " 'foot_tall': 108.99311708951214,\n",
       " 'lower_half': 120.12882888361816,\n",
       " 'hourglass_figure': 133.77206645898235,\n",
       " 'average_height': 138.38654810217236,\n",
       " 'took_chance': 285.1343620918089,\n",
       " 'form_fitting': 407.06698265726044,\n",
       " 'others_mentioned': 138.417821098277,\n",
       " 'dry_cleaned': 448.1302179962894,\n",
       " 'month_ago': 216.71853769006793,\n",
       " 'added_bonus': 335.35881638320024,\n",
       " 'pilcro_stet': 199.5185854414042,\n",
       " 'reasonably_priced': 1006.42578125,\n",
       " 'visual_interest': 1396.870481927711,\n",
       " 'cowl_neck': 206.78998216409036,\n",
       " 'elastic_waistband': 149.0776100628931,\n",
       " 'cant_wait': 164.8239229912394,\n",
       " 'wish_list': 122.41904239766082,\n",
       " 'couldve_gotten': 120.84662288930582,\n",
       " 'football_player': 5367.604166666666,\n",
       " 'cami_underneath': 109.93020846031939,\n",
       " 'baby_doll': 1015.4164477141355,\n",
       " 'body_type': 118.75869062526408,\n",
       " 'last_week': 106.27059220558459,\n",
       " 'cold_water': 614.9551440329218,\n",
       " 'burnt_orange': 358.9524166755975,\n",
       " 'real_life': 838.8441860465117,\n",
       " 'caught_eye': 714.9971651945572,\n",
       " 'scoop_neck': 151.03327586206896,\n",
       " 'gave_star': 261.73460317460314,\n",
       " 'numerous_compliment': 129.8286722096246,\n",
       " 'hot_humid': 463.2922572456103,\n",
       " 'broad_shoulder': 123.89690953001774,\n",
       " 'strapless_bra': 121.63141350405306,\n",
       " 'year_round': 236.99666551684487,\n",
       " 'reviewer_mentioned': 116.63080153743624,\n",
       " 'hide_tummy': 139.68284087828678,\n",
       " 'dry_clean': 540.513986013986,\n",
       " 'add_interest': 144.12155765920824,\n",
       " 'forest_green': 126.39570251177393,\n",
       " 'reviewer_noted': 105.76198132247802,\n",
       " 'sensitive_skin': 229.29571197411005,\n",
       " 'read_review': 107.71528297445518,\n",
       " 'ended_buying': 102.04570659062104,\n",
       " 'holiday_party': 382.87223631750635,\n",
       " 'based_review': 101.69542970246825,\n",
       " 'title_say': 187.10602759622367,\n",
       " 'pleasantly_surprised': 783.3163003663004,\n",
       " 'ballet_flat': 237.3295873249816,\n",
       " 'pear_shaped': 1038.629377676997,\n",
       " 'peachy_pink': 139.56933911159263,\n",
       " 'cooler_weather': 146.00632083696598,\n",
       " 'metallic_thread': 396.74314752078845,\n",
       " 'raw_edge': 904.0175438596491,\n",
       " 'machine_washable': 1396.7567765567765,\n",
       " 'statement_necklace': 371.91627571273904,\n",
       " 'week_ago': 214.88323603002502,\n",
       " 'agree_reviewer': 109.88951502881899,\n",
       " 'fully_lined': 383.4002976190476,\n",
       " 'new_favorite': 121.57162116616111,\n",
       " 'pilcro_hyphen': 250.27331331684917,\n",
       " 'hyphen_chino': 1036.9613003095974,\n",
       " 'vertical_stripe': 155.044380923725,\n",
       " 'trying_decide': 141.3958544410672,\n",
       " 'gentle_cycle': 1417.0475,\n",
       " 'tumble_dry': 167.30194805194805,\n",
       " 'highly_recommend': 215.97772546093395,\n",
       " 'excited_receive': 230.74366535605068,\n",
       " 'rehearsal_dinner': 1081.5682158920538,\n",
       " 'wont_regret': 256.9283052537658,\n",
       " 'polka_dot': 1756.0318974918212,\n",
       " 'ton_compliment': 147.76752855709026,\n",
       " 'paying_full': 117.30331451466036,\n",
       " 'cloth_stone': 2012.8515625,\n",
       " 'last_year': 100.73972703168339,\n",
       " 'pay_shipping': 129.1453634085213,\n",
       " 'year_ago': 143.54457127327083,\n",
       " 'camisole_underneath': 102.07805071315373,\n",
       " 'nude_bra': 113.97036226485379,\n",
       " 'exceeded_expectation': 2613.0324543610545,\n",
       " 'previous_reviewer': 117.39043744380244,\n",
       " 'light_airy': 107.51350806886776,\n",
       " 'adding_bulk': 223.94176445023905,\n",
       " 'rave_review': 107.26269775187345,\n",
       " 'boiled_wool': 947.2242647058823,\n",
       " 'first_sight': 169.64466002370395,\n",
       " 'paid_full': 176.34168599566522,\n",
       " 'year_old': 116.54934702226417,\n",
       " 'rib_cage': 3133.5202702702704,\n",
       " 'wiggle_room': 257.13073852295406,\n",
       " 'byron_lars': 6870.533333333334,\n",
       " 'everywhere_else': 273.25984848484853,\n",
       " 'online_exclusive': 109.1379775107825,\n",
       " 'mustard_yellow': 144.03633822501746,\n",
       " 'washing_instruction': 178.5791024085947,\n",
       " 'tag_say': 102.90831517792303,\n",
       " 'get_colder': 180.04542278127184,\n",
       " 'olive_green': 109.54294217687074,\n",
       " 'personal_preference': 2246.2510897994766,\n",
       " 'drive_crazy': 357.34396671289875,\n",
       " 'faux_leather': 242.02118776745644,\n",
       " 'raise_arm': 110.97734321157823,\n",
       " 'horizontal_stripe': 250.7358347750865,\n",
       " 'ever_owned': 290.75924764890283,\n",
       " 'inner_lining': 122.0540482342808,\n",
       " 'looking_forward': 124.76878755534473,\n",
       " 'hour_glass': 764.8494486853266,\n",
       " 'hd_paris': 5112.003968253968,\n",
       " 'plenty_room': 153.51088867042037,\n",
       " 'pale_skin': 175.9399958433538,\n",
       " 'special_occasion': 126.04354004565998,\n",
       " 'faux_fur': 1602.2699004975125,\n",
       " 'broad_shouldered': 604.8004694835681,\n",
       " 'gift_card': 734.031339031339,\n",
       " 'slight_sheen': 187.78790087463557,\n",
       " 'reading_review': 144.3661466597542,\n",
       " 'bathing_suit': 604.6730856025275,\n",
       " 'beach_coverup': 376.9954883550787,\n",
       " 'outer_shell': 273.36339522546416,\n",
       " 'baby_bump': 150.60109112164707,\n",
       " 'lie_flat': 106.1390654425612,\n",
       " 'flip_flop': 4558.9357937310415,\n",
       " 'write_review': 127.80236327882794,\n",
       " 'become_goto': 147.81698221457256,\n",
       " 'opened_package': 801.4974547511312,\n",
       " 'washing_drying': 117.69986295111923,\n",
       " 'athletic_build': 567.2675371223759,\n",
       " 'mid_section': 487.9640151515152,\n",
       " 'quickly_become': 142.7198448968287,\n",
       " 'highly_recommended': 150.1427738927739,\n",
       " 'degree_weather': 130.5633445945946,\n",
       " 'cover_bum': 171.45851818988464,\n",
       " 'cant_speak': 109.17161016949152,\n",
       " 'add_bulk': 112.07085622710623,\n",
       " 'description_say': 278.5488230379871,\n",
       " 'bell_shaped': 102.09827620368536,\n",
       " 'around_house': 290.95990965556183,\n",
       " 'dressing_room': 222.84664005322688,\n",
       " 'prettier_person': 126.81806994995762,\n",
       " 'laid_flat': 102.34838453389831,\n",
       " 'cowboy_boot': 149.31614024920313,\n",
       " 'please_bring': 172.8001341381623,\n",
       " 'dusty_rose': 627.7899610136452,\n",
       " 'worth_penny': 384.01570740655814,\n",
       " 'addition_wardrobe': 166.76051779935275,\n",
       " 'finger_crossed': 2817.9921875,\n",
       " 'slimming_effect': 155.90862542475446,\n",
       " 'lay_flat': 151.39031878972457,\n",
       " 'couldnt_resist': 283.7375005506366,\n",
       " 'christmas_gift': 155.44193061840122,\n",
       " 'outer_layer': 139.38529163144548,\n",
       " 'start_saying': 380.6119318181818,\n",
       " 'cocktail_party': 289.4887640449438,\n",
       " 'birthday_gift': 287.22965440356745,\n",
       " 'live_south': 113.6000881834215,\n",
       " 'swim_suit': 115.31425831202047,\n",
       " 'pleasant_surprise': 760.8564045773347,\n",
       " 'computer_screen': 1808.0350877192982,\n",
       " 'army_green': 176.95398351648353,\n",
       " 'immediately_drawn': 163.89631043256998,\n",
       " 'post_baby': 439.4589216336587,\n",
       " 'hei_hei': 1958.102,\n",
       " 'warmer_weather': 156.3207391064534,\n",
       " 'mara_hoffman': 12882.25,\n",
       " 'month_pregnant': 199.32306978183507,\n",
       " 'followed_advice': 600.5710955710956,\n",
       " 'deal_breaker': 1396.672512755102,\n",
       " 'running_errand': 695.8818955639222,\n",
       " 'strap_adjustable': 107.62113617376775,\n",
       " 'worth_money': 126.96875616006307,\n",
       " 'stop_thinking': 119.35113493481569,\n",
       " 'live_florida': 227.200176366843,\n",
       " 'spend_money': 271.88497559688693,\n",
       " 'post_partum': 1206.768149882904,\n",
       " 'washed_according': 191.8071840684906,\n",
       " 'stevie_ankle': 110.78646370829033,\n",
       " 'chemical_smell': 1192.8009259259259,\n",
       " 'fur_collar': 144.33893557422968,\n",
       " 'bridal_shower': 3809.2674731182797,\n",
       " 'sewn_shut': 676.9951201201202,\n",
       " 'free_shipping': 1051.6122448979593,\n",
       " 'turtle_neck': 194.34428879310346,\n",
       " 'hide_imperfection': 270.63550420168065,\n",
       " 'birthday_discount': 315.5480710349051,\n",
       " 'widest_part': 134.03884505332525,\n",
       " 'disagree_previous': 132.8323773925372,\n",
       " 'hug_place': 112.0400759864506,\n",
       " 'pay_full': 132.94375644994838,\n",
       " 'lump_bump': 1752.1688350088705,\n",
       " 'delicate_cycle': 174.67457627118645,\n",
       " 'put_together': 119.07396616163646,\n",
       " 'pet_peeve': 3680.642857142857,\n",
       " 'hook_eye': 309.99346097509937,\n",
       " 'customer_service': 2924.0920554854983,\n",
       " 'kelly_green': 176.95398351648353,\n",
       " 'date_night': 380.9062684801892,\n",
       " 'safety_pin': 2081.979797979798,\n",
       " 'teeny_tiny': 111.38996973627323,\n",
       " 'upcoming_trip': 377.5018315018315,\n",
       " 'took_plunge': 183.19941822882998,\n",
       " 'eva_franco': 12723.20987654321,\n",
       " 'muscular_thigh': 172.99904076738608,\n",
       " 'get_cooler': 153.90979689366785,\n",
       " 'missed_mark': 339.4532279314888,\n",
       " 'mock_neck': 197.42911877394636,\n",
       " 'tennis_shoe': 232.7416440831075,\n",
       " 'colder_month': 121.09816692405828,\n",
       " 'according_direction': 353.4224965706447,\n",
       " 'air_dry': 144.780531968032,\n",
       " 'skin_tone': 273.2630333686873,\n",
       " 'dry_cleaning': 481.6268201495474,\n",
       " 'post_pregnancy': 263.98053278688525,\n",
       " 'heeled_sandal': 103.88911290322581,\n",
       " 'accentuates_curve': 144.33893557422968,\n",
       " 'ag_stevie': 894.6006944444443,\n",
       " 'knitted_knotted': 722.7068723702664,\n",
       " 'falling_apart': 178.45541125541126,\n",
       " 'holding_horse': 2450.717535153019,\n",
       " 'strappy_sandal': 180.6767180925666,\n",
       " 'couldnt_happier': 291.8748779249189,\n",
       " 'moulinette_soeurs': 4294.083333333333,\n",
       " 'let_start': 143.40166975881263,\n",
       " 'mid_thigh': 154.4634292565947,\n",
       " 'meet_expectation': 161.5329153605016,\n",
       " 'trouble_finding': 114.67197792415881,\n",
       " 'mock_turtleneck': 275.26175213675214,\n",
       " 'room_spare': 264.4773310521814,\n",
       " 'colder_weather': 118.24604793472717,\n",
       " 'care_instruction': 195.9774340770791,\n",
       " 'knocked_star': 286.27222222222224,\n",
       " 'crushed_velvet': 221.34450171821305,\n",
       " 'air_dried': 291.45361990950227,\n",
       " 'potato_sack': 1261.8059381695746,\n",
       " 'meadow_rue': 8922.770562770564,\n",
       " 'everyone_else': 124.27321274763135,\n",
       " 'hug_curve': 130.12373737373738,\n",
       " 'audrey_hepburn': 6134.4047619047615,\n",
       " 'lounging_around': 128.0223602484472,\n",
       " 'new_england': 249.65600775193798,\n",
       " 'southern_california': 1981.8846153846155,\n",
       " 'gape_open': 112.5283892382949,\n",
       " 'eye_catching': 740.8073547215497,\n",
       " 'natural_fiber': 483.3864915572233,\n",
       " 'defeat_purpose': 2094.674796747968,\n",
       " 'swim_coverup': 218.34322033898303,\n",
       " 'broad_shouldersback': 691.2005365526492,\n",
       " 'dry_cleaner': 334.6038961038961,\n",
       " 'blown_away': 268.66006256517204,\n",
       " 'comfort_zone': 245.3761904761905,\n",
       " 'angel_north': 5855.568181818182,\n",
       " 'charlie_trouser': 510.86252478519503,\n",
       " 'trench_coat': 114.12846068660023,\n",
       " 'aesthetically_pleasing': 2453.761904761905,\n",
       " 'retro_vibe': 106.35500515995872,\n",
       " 'weather_warms': 107.12889812889813,\n",
       " 'dragging_ground': 639.317617866005,\n",
       " 'pilcro_serif': 144.09675615212527,\n",
       " 'left_center': 142.73961218836567,\n",
       " 'taking_tailor': 104.0989898989899,\n",
       " 'jewel_tone': 333.08985132514545,\n",
       " 'associate_suggested': 194.30241327300152,\n",
       " 'citizen_humanity': 3505.3741496598636,\n",
       " 'frayed_edge': 100.44639376218323,\n",
       " 'mid_calf': 112.17563566701497,\n",
       " 'draw_string': 507.6748768472906,\n",
       " 'pom_pom': 1590.4012345679012,\n",
       " 'stain_remover': 1561.4848484848485,\n",
       " 'vegan_leather': 211.96626902509257,\n",
       " 'curvymuscular_frame': 221.59833715596332}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram.export_phrases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tracy_reese': 1695973.5,\n",
       " 'foot_tall': 165.5492240418417,\n",
       " 'lower_half': 159.49865780730894,\n",
       " 'hourglass_figure': 221.19590250794772,\n",
       " 'average_height': 176.4025691105769,\n",
       " 'took_chance': 785.1345200254291,\n",
       " 'form_fitting': 2053.6028676021965,\n",
       " 'others_mentioned': 406.0845623656711,\n",
       " 'dry_cleaned': 3519.590827338129,\n",
       " 'month_ago': 4177.274630541872,\n",
       " 'someone_else': 129.3399014778325,\n",
       " 'added_bonus': 547.8422452407615,\n",
       " 'pilcro_stet': 395.33181818181816,\n",
       " 'reasonably_priced': 5017.673076923077,\n",
       " 'lot_compliment': 109.63923334190892,\n",
       " 'visual_interest': 10299.434210526315,\n",
       " 'cowl_neck': 549.6031362146981,\n",
       " 'warmer_climate': 111.36107554417414,\n",
       " 'elastic_waistband': 206.3522797606767,\n",
       " 'cant_wait': 694.4332592291073,\n",
       " 'wish_list': 316.1770134228188,\n",
       " 'couldve_gotten': 163.89384422110552,\n",
       " 'football_player': 104367.6,\n",
       " 'cami_underneath': 207.74361702127658,\n",
       " 'baby_doll': 16583.83474576271,\n",
       " 'body_type': 340.69760229813767,\n",
       " 'last_week': 243.6425297113752,\n",
       " 'cold_water': 2272.2675675675678,\n",
       " 'hang_dry': 117.82757170886667,\n",
       " 'burnt_orange': 921.9752650176679,\n",
       " 'real_life': 3765.8412371134023,\n",
       " 'caught_eye': 6412.649841437632,\n",
       " 'hide_flaw': 119.5048854961832,\n",
       " 'scoop_neck': 321.32881773399015,\n",
       " 'gave_star': 483.4631152287203,\n",
       " 'numerous_compliment': 509.0392976588629,\n",
       " 'hot_humid': 2084.409304511278,\n",
       " 'disagree_reviewer': 115.33026601301937,\n",
       " 'broad_shoulder': 679.5814361784227,\n",
       " 'strapless_bra': 284.64900750359214,\n",
       " 'year_round': 1186.8383795309169,\n",
       " 'reading_previous': 202.60832427395556,\n",
       " 'previous_review': 244.16900617630543,\n",
       " 'reviewer_mentioned': 458.87805753459077,\n",
       " 'read_previous': 151.68729410244816,\n",
       " 'cold_weather': 108.71625,\n",
       " 'hide_tummy': 200.7069230769231,\n",
       " 'dry_clean': 3845.796806457273,\n",
       " 'add_interest': 353.511933298593,\n",
       " 'forest_green': 490.44924812030075,\n",
       " 'reviewer_noted': 249.46044999681305,\n",
       " 'sensitive_skin': 538.6841216216216,\n",
       " 'read_review': 352.27321307011573,\n",
       " 'ended_buying': 141.2243241048957,\n",
       " 'holiday_party': 811.1061490636135,\n",
       " 'based_review': 311.75565149136577,\n",
       " 'title_say': 460.5807590467785,\n",
       " 'pleasantly_surprised': 34050.75,\n",
       " 'ballet_flat': 918.7288732394367,\n",
       " 'pear_shaped': 3649.2167832167834,\n",
       " 'peachy_pink': 268.98865979381446,\n",
       " 'cooler_weather': 302.8524107142857,\n",
       " 'metallic_thread': 731.0703278229196,\n",
       " 'raw_edge': 2981.9314285714286,\n",
       " 'machine_washable': 6662.527950310559,\n",
       " 'statement_necklace': 630.2391304347826,\n",
       " 'week_ago': 4208.370967741936,\n",
       " 'reviewer_stated': 115.04169987620614,\n",
       " 'agree_reviewer': 332.1432532347505,\n",
       " 'fully_lined': 1439.705857385399,\n",
       " 'new_favorite': 219.02302434344645,\n",
       " 'pilcro_hyphen': 988.3295454545455,\n",
       " 'vertical_stripe': 280.2567132116004,\n",
       " 'trying_decide': 210.5491620111732,\n",
       " 'gentle_cycle': 6294.098684210526,\n",
       " 'tumble_dry': 1251.410071942446,\n",
       " 'based_previous': 129.5590645017131,\n",
       " 'highly_recommend': 4021.981980026053,\n",
       " 'excited_receive': 454.02253628724213,\n",
       " 'rehearsal_dinner': 7247.75,\n",
       " 'wont_regret': 426.8889175923534,\n",
       " 'polka_dot': 171657.23684210528,\n",
       " 'ton_compliment': 448.7856665074056,\n",
       " 'paying_full': 234.87172562786927,\n",
       " 'cloth_stone': 13713.072443181818,\n",
       " 'last_year': 273.2851531814611,\n",
       " 'pay_shipping': 439.25757575757575,\n",
       " 'year_ago': 3326.392723880597,\n",
       " 'camisole_underneath': 195.21646013560905,\n",
       " 'nude_bra': 240.31222657149434,\n",
       " 'exceeded_expectation': 36238.75,\n",
       " 'not_wait': 249.89721746143763,\n",
       " 'previous_reviewer': 380.1995763455078,\n",
       " 'light_airy': 222.99454791936816,\n",
       " 'adding_bulk': 463.856,\n",
       " 'boiled_wool': 35704.7052631579,\n",
       " 'first_sight': 2241.572164948454,\n",
       " 'paid_full': 388.94757763975156,\n",
       " 'paid_full_price': 138.61321875000002,\n",
       " 'year_old': 295.6079503472735,\n",
       " 'wiggle_room': 1441.5414364640883,\n",
       " 'byron_lars': 6262056.0,\n",
       " 'byron_lars_dress': 346.07701830400566,\n",
       " 'everywhere_else': 534.2790697674419,\n",
       " 'mustard_yellow': 202.02787456445992,\n",
       " 'washing_instruction': 342.97601051593824,\n",
       " 'tag_say': 169.90936538006156,\n",
       " 'get_colder': 674.2093023255815,\n",
       " 'olive_green': 192.4781954887218,\n",
       " 'personal_preference': 7412.471590909091,\n",
       " 'drive_crazy': 776.5446428571428,\n",
       " 'love_first_sight': 162.338777414839,\n",
       " 'faux_leather': 836.8749109052031,\n",
       " 'raise_arm': 522.7790022039671,\n",
       " 'horizontal_stripe': 490.44924812030075,\n",
       " 'ever_owned': 570.8462037112066,\n",
       " 'inner_lining': 182.43764302059498,\n",
       " 'looking_forward': 312.7645037000795,\n",
       " 'hour_glass': 2558.029411764706,\n",
       " 'hd_paris': 48318.33333333333,\n",
       " 'plenty_room': 323.9418958346266,\n",
       " 'pale_skin': 333.73023023023023,\n",
       " 'special_occasion': 168.05603606919396,\n",
       " 'faux_fur': 12330.765595463137,\n",
       " 'broad_shouldered': 10871.625,\n",
       " 'gift_card': 5116.058823529412,\n",
       " 'slight_sheen': 262.4059671471673,\n",
       " 'reading_review': 761.5475450081833,\n",
       " 'bathing_suit': 34377.84121621621,\n",
       " 'beach_coverup': 733.2618266978923,\n",
       " 'outer_shell': 641.0786240786241,\n",
       " 'baby_bump': 315.88256658595645,\n",
       " 'week_pregnant': 114.40231756968367,\n",
       " 'lie_flat': 214.3700704225352,\n",
       " 'flip_flop': 507342.5,\n",
       " 'write_review': 669.0230769230769,\n",
       " 'become_goto': 156.05203349282297,\n",
       " 'opened_package': 1818.2508710801394,\n",
       " 'washing_drying': 194.3530726256983,\n",
       " 'athletic_build': 2000.983948635634,\n",
       " 'mid_section': 1471.3477443609022,\n",
       " 'quickly_become': 202.73426573426573,\n",
       " 'highly_recommended': 2650.6057142857144,\n",
       " 'degree_weather': 266.24387755102043,\n",
       " 'cover_bum': 259.19105960264903,\n",
       " 'cant_speak': 508.8620185275475,\n",
       " 'add_bulk': 218.15009900990097,\n",
       " 'positive_review': 105.63522267206477,\n",
       " 'description_say': 525.7572815533981,\n",
       " 'bell_shaped': 213.51800327332242,\n",
       " 'around_house': 358.6126302083333,\n",
       " 'dressing_room': 594.9218626677191,\n",
       " 'prettier_person': 406.8383575883576,\n",
       " 'emerald_green': 104.62917293233083,\n",
       " 'christmas_party': 113.49238799478034,\n",
       " 'laid_flat': 194.55434962717482,\n",
       " 'hate_paying': 120.68408880666051,\n",
       " 'cowboy_boot': 436.31939799331104,\n",
       " 'please_bring': 229.30734463276838,\n",
       " 'laid_flat_dry': 220.8370715192552,\n",
       " 'dusty_rose': 1162.74064171123,\n",
       " 'worth_penny': 4522.596,\n",
       " 'pay_attention': 130.32917082917083,\n",
       " 'addition_wardrobe': 263.38104015799865,\n",
       " 'finger_crossed': 13380.461538461537,\n",
       " 'slimming_effect': 210.4316024567281,\n",
       " 'lay_flat': 289.91,\n",
       " 'couldnt_resist': 915.7623192475081,\n",
       " 'pilcro_chino': 106.84643734643736,\n",
       " 'others_noted': 120.19169518294288,\n",
       " 'christmas_gift': 269.26625386996903,\n",
       " 'outer_layer': 259.9765848798107,\n",
       " 'cocktail_party': 680.954327968682,\n",
       " 'birthday_gift': 653.1138923654569,\n",
       " 'live_south': 174.99597585513078,\n",
       " 'swim_suit': 293.8277027027027,\n",
       " 'washing_cold_water': 118.18767929941114,\n",
       " 'pleasant_surprise': 2249.301724137931,\n",
       " 'computer_screen': 5435.8125,\n",
       " 'washed_cold_water': 183.16532116532116,\n",
       " 'hung_dry': 174.61535887569013,\n",
       " 'army_green': 2354.1563909774436,\n",
       " 'immediately_drawn': 231.69036885245902,\n",
       " 'post_baby': 1730.4871039056743,\n",
       " 'hei_hei': 1239365.25,\n",
       " 'warmer_weather': 288.7433601609658,\n",
       " 'month_pregnant': 374.3636711463963,\n",
       " 'followed_advice': 993.9771428571429,\n",
       " 'running_errand': 1762.9662162162163,\n",
       " 'strap_adjustable': 147.8893117408907,\n",
       " 'worth_money': 253.67125,\n",
       " 'fair_skin': 117.53108108108108,\n",
       " 'stop_thinking': 154.7955758962624,\n",
       " 'live_florida': 341.85260399606943,\n",
       " 'bathing_suit_cover': 1295.955298013245,\n",
       " 'spend_money': 592.9977272727273,\n",
       " 'washed_according': 417.05334665334664,\n",
       " 'dry_shrunk': 110.4185357596276,\n",
       " 'chemical_smell': 4254.114130434782,\n",
       " 'bridal_shower': 68335.92857142858,\n",
       " 'sewn_shut': 2238.275735294118,\n",
       " 'free_shipping': 3221.222222222222,\n",
       " 'turtle_neck': 926.1830628803245,\n",
       " 'hide_imperfection': 549.3031578947368,\n",
       " 'birthday_discount': 555.1468085106383,\n",
       " 'widest_part': 328.3376677852349,\n",
       " 'disagree_previous': 331.2205649000317,\n",
       " 'hug_place': 187.7683887584274,\n",
       " 'pay_full': 278.28740824393,\n",
       " 'lump_bump': 12247.218367346939,\n",
       " 'say_dry_clean': 247.14089509827136,\n",
       " 'delicate_cycle': 490.44924812030075,\n",
       " 'ample_room': 128.70905682715076,\n",
       " 'put_together': 189.8493198354951,\n",
       " 'pet_peeve': 65229.75,\n",
       " 'hook_eye': 1316.6162790697674,\n",
       " 'customer_service': 41197.73684210526,\n",
       " 'kelly_green': 2354.1563909774436,\n",
       " 'date_night': 915.8266058266058,\n",
       " 'teeny_tiny': 189.7592727272727,\n",
       " 'pear_shape': 133.07848457646483,\n",
       " 'upcoming_trip': 575.5566176470588,\n",
       " 'took_plunge': 439.25757575757575,\n",
       " 'muscular_thigh': 281.1627155172414,\n",
       " 'get_cooler': 303.3941860465116,\n",
       " 'missed_mark': 514.6331360946746,\n",
       " 'mock_neck': 1411.3265720081135,\n",
       " 'tennis_shoe': 743.3589743589744,\n",
       " 'colder_month': 499.84482758620686,\n",
       " 'hyphen_chino': 1923.2358722358722,\n",
       " 'air_dry': 563.1345323741007,\n",
       " 'skin_tone': 647.2726204465334,\n",
       " 'dry_cleaning': 3962.7985611510794,\n",
       " 'post_pregnancy': 850.8228260869565,\n",
       " 'mid_rise': 130.23809523809524,\n",
       " 'heeled_sandal': 173.02320954907162,\n",
       " 'accentuates_curve': 227.47951176983435,\n",
       " 'ag_stevie': 3010.6038461538465,\n",
       " 'knitted_knotted': 1358.953125,\n",
       " 'falling_apart': 232.54812834224597,\n",
       " 'couldnt_wait': 105.69073372599681,\n",
       " 'holding_horse': 16045.820855614975,\n",
       " 'strappy_sandal': 321.32881773399015,\n",
       " 'couldnt_happier': 950.4648913453084,\n",
       " 'let_start': 198.38396553180704,\n",
       " 'mid_thigh': 392.7352216748768,\n",
       " 'meet_expectation': 301.9895833333333,\n",
       " 'trouble_finding': 142.6722440944882,\n",
       " 'mock_turtleneck': 1831.0105263157895,\n",
       " 'room_spare': 942.5463238419039,\n",
       " 'reviewer_pointed': 109.61140984708453,\n",
       " 'colder_weather': 465.9267857142857,\n",
       " 'elastic_band': 108.69926573972816,\n",
       " 'care_instruction': 368.35623529411765,\n",
       " 'knocked_star': 3162.6545454545453,\n",
       " 'crushed_velvet': 477.8736263736264,\n",
       " 'air_dried': 606.7883720930232,\n",
       " 'potato_sack': 6957.84,\n",
       " 'washing_machine': 115.68635275339186,\n",
       " 'nude_colored': 108.28440149404162,\n",
       " 'everyone_else': 208.85454545454544,\n",
       " 'let_start_saying': 161.24358842311256,\n",
       " 'hook_eye_closure': 182.33333333333331,\n",
       " 'hug_curve': 232.32888120678817,\n",
       " 'lounging_around': 198.87118902439025,\n",
       " 'label_say': 103.39568060233802,\n",
       " 'southern_california': 6212.357142857142,\n",
       " 'caught_attention': 195.49375624375625,\n",
       " 'gape_open': 162.91146353646354,\n",
       " 'sport_bra': 110.12493141434179,\n",
       " 'eye_catching': 14411.223837209303,\n",
       " 'natural_fiber': 861.7508256880734,\n",
       " 'defeat_purpose': 23719.909090909092,\n",
       " 'swim_coverup': 709.9836734693877,\n",
       " 'broad_shouldersback': 47439.818181818184,\n",
       " 'baby_shower': 315.88256658595645,\n",
       " 'body_skimming': 111.86237942122186,\n",
       " 'paid_attention': 172.03450549450548,\n",
       " 'dry_cleaner': 1877.1151079136691,\n",
       " 'comfort_zone': 1811.9375,\n",
       " 'running_around': 165.2780827702703,\n",
       " 'angel_north': 130459.5,\n",
       " 'ton_complement': 103.53928571428571,\n",
       " 'charlie_trouser': 1073.7407407407409,\n",
       " 'trench_coat': 188.62750768118562,\n",
       " 'hourglass_shaped': 101.0269747031492,\n",
       " 'free_people': 101.27860262008733,\n",
       " 'aesthetically_pleasing': 28991.0,\n",
       " 'retro_vibe': 133.80461538461537,\n",
       " 'weather_warms': 310.6178571428572,\n",
       " 'fyi_broad_shouldersback': 20070.69230769231,\n",
       " 'dragging_ground': 1490.9657142857143,\n",
       " 'pilcro_serif': 395.33181818181816,\n",
       " 'left_center': 187.18966908797418,\n",
       " 'taking_tailor': 128.38395932425783,\n",
       " 'draw_attention': 110.27852916314454,\n",
       " 'jewel_tone': 1260.4782608695652,\n",
       " 'associate_suggested': 282.37987012987014,\n",
       " 'frayed_edge': 160.3188940092166,\n",
       " 'mid_calf': 268.93320964749535,\n",
       " 'draw_string': 819.2119309262167,\n",
       " 'waste_money': 125.44182692307693,\n",
       " 'pom_pom': 32614.875,\n",
       " 'stain_remover': 7051.864864864865,\n",
       " 'vegan_leather': 427.7360655737705,\n",
       " 'chunky_necklace': 114.58893280632411}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram.export_phrases()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m spacy download en  # run in terminal once\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "def process_words(texts):\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    return texts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = process_words(data_words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love',\n",
       " 'tracy_reese',\n",
       " 'dress',\n",
       " 'petite',\n",
       " 'foot_tall',\n",
       " 'usually',\n",
       " 'wear',\n",
       " 'brand',\n",
       " 'dress',\n",
       " 'pretty',\n",
       " 'package',\n",
       " 'dress',\n",
       " 'skirt',\n",
       " 'long',\n",
       " 'full',\n",
       " 'overwhelmed',\n",
       " 'small',\n",
       " 'frame',\n",
       " 'stranger',\n",
       " 'alteration',\n",
       " 'shortening',\n",
       " 'narrowing',\n",
       " 'skirt',\n",
       " 'away',\n",
       " 'embellishment',\n",
       " 'garment',\n",
       " 'love',\n",
       " 'color',\n",
       " 'idea',\n",
       " 'style',\n",
       " 'work',\n",
       " 'returned',\n",
       " 'dress']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Gensim 모델링을 위한 Dictionary 세트 준비 \n",
    "import gensim.corpora as corpora\n",
    "dictionary = corpora.Dictionary(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolutely\n",
      "comfortable\n",
      "sexy\n",
      "silky\n",
      "wonderful\n",
      "bc\n",
      "bought\n",
      "definitely\n",
      "dress\n",
      "find\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 10):\n",
    "    print(dictionary.get(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary size : 16508\n"
     ]
    }
   ],
   "source": [
    "print('dictionary size : %d' % len(dictionary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary size : 2087\n"
     ]
    }
   ],
   "source": [
    "# 필터링\n",
    "from collections import Counter\n",
    "min_count = 20\n",
    "word_counter = Counter((word for words in documents for word in words))\n",
    "removal_word_idxs = {dictionary.token2id[word] for word, count in word_counter.items() if count < min_count}\n",
    "dictionary.filter_tokens(removal_word_idxs)\n",
    "dictionary.compactify()\n",
    "print('dictionary size : %d' % len(dictionary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1)]\n"
     ]
    }
   ],
   "source": [
    "# 말뭉치 생성\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [dictionary.doc2bow(text) for text in documents]\n",
    "# View\n",
    "print(corpus[:1][0][:30])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Base LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                            id2word=dictionary,\n",
    "                                            num_topics=4,\n",
    "                                            random_state=1969,\n",
    "                                            per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.033*\"love\" + 0.026*\"great\" + 0.022*\"dress\" + 0.019*\"wear\" + 0.019*\"color\" '\n",
      "  '+ 0.016*\"fit\" + 0.016*\"perfect\" + 0.015*\"comfortable\" + 0.013*\"look\" + '\n",
      "  '0.012*\"bought\"'),\n",
      " (1,\n",
      "  '0.045*\"size\" + 0.025*\"fit\" + 0.021*\"small\" + 0.017*\"ordered\" + 0.017*\"im\" + '\n",
      "  '0.016*\"dress\" + 0.013*\"petite\" + 0.011*\"love\" + 0.011*\"wear\" + '\n",
      "  '0.009*\"large\"'),\n",
      " (2,\n",
      "  '0.036*\"dress\" + 0.020*\"fit\" + 0.016*\"look\" + 0.015*\"fabric\" + 0.015*\"color\" '\n",
      "  '+ 0.015*\"size\" + 0.014*\"top\" + 0.011*\"im\" + 0.010*\"love\" + 0.009*\"little\"'),\n",
      " (3,\n",
      "  '0.043*\"top\" + 0.017*\"look\" + 0.016*\"im\" + 0.016*\"back\" + 0.013*\"really\" + '\n",
      "  '0.012*\"cute\" + 0.011*\"love\" + 0.010*\"small\" + 0.010*\"fit\" + 0.009*\"fabric\"')]\n"
     ]
    }
   ],
   "source": [
    "# 토픽 인쇄\n",
    "from pprint import pprint\n",
    "pprint(lda_model.print_topics())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.033*\"love\" + 0.026*\"great\" + 0.022*\"dress\" + 0.019*\"wear\" + 0.019*\"color\" '\n",
      "  '+ 0.016*\"fit\" + 0.016*\"perfect\" + 0.015*\"comfortable\" + 0.013*\"look\" + '\n",
      "  '0.012*\"bought\"'),\n",
      " (1,\n",
      "  '0.045*\"size\" + 0.025*\"fit\" + 0.021*\"small\" + 0.017*\"ordered\" + 0.017*\"im\" + '\n",
      "  '0.016*\"dress\" + 0.013*\"petite\" + 0.011*\"love\" + 0.011*\"wear\" + '\n",
      "  '0.009*\"large\"'),\n",
      " (2,\n",
      "  '0.036*\"dress\" + 0.020*\"fit\" + 0.016*\"look\" + 0.015*\"fabric\" + 0.015*\"color\" '\n",
      "  '+ 0.015*\"size\" + 0.014*\"top\" + 0.011*\"im\" + 0.010*\"love\" + 0.009*\"little\"'),\n",
      " (3,\n",
      "  '0.043*\"top\" + 0.017*\"look\" + 0.016*\"im\" + 0.016*\"back\" + 0.013*\"really\" + '\n",
      "  '0.012*\"cute\" + 0.011*\"love\" + 0.010*\"small\" + 0.010*\"fit\" + 0.009*\"fabric\"')]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(lda_model=None, corpus=corpus, documents=documents):\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "    for i, row_list in enumerate(lda_model[corpus]):\n",
    "        # pprint(row_list[0])\n",
    "        row = row_list[0] if lda_model.per_word_topics else row_list \n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # pprint(row)\n",
    "        # print(i)\n",
    "        # pprint(row_list)\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0: # => dominant topic\n",
    "                wp = lda_model.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                new_row = pd.DataFrame([int(topic_num),round(prop_topic,4), topic_keywords]).T\n",
    "                sent_topics_df = pd.concat([new_row, sent_topics_df.loc[:]]).reset_index(drop=True)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        #break;\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(documents)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    sent_topics_df.columns = ['Dominant_Topic','Perc_Contribution','Topic_Keywords','Text']\n",
    "    return sent_topics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_df = format_topics_sentences(lda_model, corpus, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22641, 4)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_topics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Perc_Contribution</th>\n",
       "      <th>Topic_Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>love, great, dress, wear, color, fit, perfect,...</td>\n",
       "      <td>[absolutely, wonderful, silky, sexy, comfortable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.7646</td>\n",
       "      <td>dress, fit, look, fabric, color, size, top, im...</td>\n",
       "      <td>[love, dress, sooo, pretty, happened, find, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>size, fit, small, ordered, im, dress, petite, ...</td>\n",
       "      <td>[high, hope, dress, really, wanted, work, init...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.5461</td>\n",
       "      <td>top, look, im, back, really, cute, love, small...</td>\n",
       "      <td>[love, love, love, jumpsuit, fun, flirty, fabu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5436</td>\n",
       "      <td>love, great, dress, wear, color, fit, perfect,...</td>\n",
       "      <td>[shirt, flattering, due, adjustable, front, ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Dominant_Topic Perc_Contribution  \\\n",
       "0              0            0.9133   \n",
       "1              2            0.7646   \n",
       "2              1            0.9494   \n",
       "3              3            0.5461   \n",
       "4              0            0.5436   \n",
       "\n",
       "                                      Topic_Keywords  \\\n",
       "0  love, great, dress, wear, color, fit, perfect,...   \n",
       "1  dress, fit, look, fabric, color, size, top, im...   \n",
       "2  size, fit, small, ordered, im, dress, petite, ...   \n",
       "3  top, look, im, back, really, cute, love, small...   \n",
       "4  love, great, dress, wear, color, fit, perfect,...   \n",
       "\n",
       "                                                Text  \n",
       "0  [absolutely, wonderful, silky, sexy, comfortable]  \n",
       "1  [love, dress, sooo, pretty, happened, find, st...  \n",
       "2  [high, hope, dress, really, wanted, work, init...  \n",
       "3  [love, love, love, jumpsuit, fun, flirty, fabu...  \n",
       "4  [shirt, flattering, due, adjustable, front, ti...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_topics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>love, great, dress, wear, color, fit, perfect,...</td>\n",
       "      <td>[absolutely, wonderful, silky, sexy, comfortable]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.7646</td>\n",
       "      <td>dress, fit, look, fabric, color, size, top, im...</td>\n",
       "      <td>[love, dress, sooo, pretty, happened, find, st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>size, fit, small, ordered, im, dress, petite, ...</td>\n",
       "      <td>[high, hope, dress, really, wanted, work, init...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5461</td>\n",
       "      <td>top, look, im, back, really, cute, love, small...</td>\n",
       "      <td>[love, love, love, jumpsuit, fun, flirty, fabu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5436</td>\n",
       "      <td>love, great, dress, wear, color, fit, perfect,...</td>\n",
       "      <td>[shirt, flattering, due, adjustable, front, ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Document_No Dominant_Topic Topic_Perc_Contrib  \\\n",
       "0            0              0             0.9133   \n",
       "1            1              2             0.7646   \n",
       "2            2              1             0.9494   \n",
       "3            3              3             0.5461   \n",
       "4            4              0             0.5436   \n",
       "\n",
       "                                            Keywords  \\\n",
       "0  love, great, dress, wear, color, fit, perfect,...   \n",
       "1  dress, fit, look, fabric, color, size, top, im...   \n",
       "2  size, fit, small, ordered, im, dress, petite, ...   \n",
       "3  top, look, im, back, really, cute, love, small...   \n",
       "4  love, great, dress, wear, color, fit, perfect,...   \n",
       "\n",
       "                                                Text  \n",
       "0  [absolutely, wonderful, silky, sexy, comfortable]  \n",
       "1  [love, dress, sooo, pretty, happened, find, st...  \n",
       "2  [high, hope, dress, really, wanted, work, init...  \n",
       "3  [love, love, love, jumpsuit, fun, flirty, fabu...  \n",
       "4  [shirt, flattering, due, adjustable, front, ti...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dominant_topic = sent_topics_df.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "df_dominant_topic.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000014E1D2EA600>\n",
      "      Dominant_Topic Perc_Contribution  \\\n",
      "14692              0            0.9828   \n",
      "13030              1            0.9809   \n",
      "12860              2            0.9839   \n",
      "17219              3            0.9811   \n",
      "\n",
      "                                                                 Topic_Keywords  \\\n",
      "14692  love, great, dress, wear, color, fit, perfect, comfortable, look, bought   \n",
      "13030           size, fit, small, ordered, im, dress, petite, love, wear, large   \n",
      "12860              dress, fit, look, fabric, color, size, top, im, love, little   \n",
      "17219               top, look, im, back, really, cute, love, small, fit, fabric   \n",
      "\n",
      "                                                                                                      Text  \n",
      "14692  [living, casual, life, style, key, largo, fl, love, fitted, tshirt, instead, boxy, shape, im, ye...  \n",
      "13030  [ordered, online, excited, unfortunately, didnt, work, maybe, style, issue, fit, maybe, im, long...  \n",
      "12860  [found, jean, fitted, slouchy, reference, im, im, heavier, thru, hip, thigh, ordered, petite, us...  \n",
      "17219  [love, print, design, photo, justice, fell, love, store, find, size, ordered, size, online, stil...  \n",
      "  Topic_Num Topic_Perc_Contrib  \\\n",
      "0         0             0.9828   \n",
      "1         1             0.9809   \n",
      "2         2             0.9839   \n",
      "3         3             0.9811   \n",
      "\n",
      "                                                                   Keywords  \\\n",
      "0  love, great, dress, wear, color, fit, perfect, comfortable, look, bought   \n",
      "1           size, fit, small, ordered, im, dress, petite, love, wear, large   \n",
      "2              dress, fit, look, fabric, color, size, top, im, love, little   \n",
      "3               top, look, im, back, really, cute, love, small, fit, fabric   \n",
      "\n",
      "                                                                                   Representative Text  \n",
      "0  [living, casual, life, style, key, largo, fl, love, fitted, tshirt, instead, boxy, shape, im, ye...  \n",
      "1  [ordered, online, excited, unfortunately, didnt, work, maybe, style, issue, fit, maybe, im, long...  \n",
      "2  [found, jean, fitted, slouchy, reference, im, im, heavier, thru, hip, thigh, ordered, petite, us...  \n",
      "3  [love, print, design, photo, justice, fell, love, store, find, size, ordered, size, online, stil...  \n"
     ]
    }
   ],
   "source": [
    "# The Most Representative Sentence for Each Topic\n",
    "pd.options.display.max_colwidth = 100\n",
    "\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "sent_topics_outdf_grpd = sent_topics_df.groupby('Dominant_Topic')\n",
    "print(sent_topics_outdf_grpd)\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], \n",
    "                                                             ascending=False).head(1)], \n",
    "                                                             axis=0)\n",
    "print(sent_topics_sorteddf_mallet.head())\n",
    "#Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "# Show\n",
    "print(sent_topics_sorteddf_mallet.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_contribute_document(sent_topics_df):\n",
    "    # The Most Representative Sentence for Each Topic\n",
    "    pd.options.display.max_colwidth = 100\n",
    "\n",
    "    sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "    sent_topics_outdf_grpd = sent_topics_df.groupby('Dominant_Topic')\n",
    "    # print(sent_topics_outdf_grpd)\n",
    "\n",
    "    for i, grp in sent_topics_outdf_grpd:\n",
    "        sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                                grp.sort_values(['Perc_Contribution'], \n",
    "                                                                ascending=False).head(1)], \n",
    "                                                                axis=0)\n",
    "    # print(sent_topics_sorteddf_mallet.head())\n",
    "    #Reset Index    \n",
    "    sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "    # Format\n",
    "    sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Representative Text\"]\n",
    "    # Show\n",
    "    # print(sent_topics_sorteddf_mallet.head())\n",
    "    return sent_topics_sorteddf_mallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_topics_sorteddf_mallet = get_most_contribute_document(sent_topics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic_Num</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Representative Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>love, great, dress, wear, color, fit, perfect, comfortable, look, bought</td>\n",
       "      <td>[living, casual, life, style, key, largo, fl, love, fitted, tshirt, instead, boxy, shape, im, ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>size, fit, small, ordered, im, dress, petite, love, wear, large</td>\n",
       "      <td>[ordered, online, excited, unfortunately, didnt, work, maybe, style, issue, fit, maybe, im, long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.9839</td>\n",
       "      <td>dress, fit, look, fabric, color, size, top, im, love, little</td>\n",
       "      <td>[found, jean, fitted, slouchy, reference, im, im, heavier, thru, hip, thigh, ordered, petite, us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>top, look, im, back, really, cute, love, small, fit, fabric</td>\n",
       "      <td>[love, print, design, photo, justice, fell, love, store, find, size, ordered, size, online, stil...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Topic_Num Topic_Perc_Contrib  \\\n",
       "0         0             0.9828   \n",
       "1         1             0.9809   \n",
       "2         2             0.9839   \n",
       "3         3             0.9811   \n",
       "\n",
       "                                                                   Keywords  \\\n",
       "0  love, great, dress, wear, color, fit, perfect, comfortable, look, bought   \n",
       "1           size, fit, small, ordered, im, dress, petite, love, wear, large   \n",
       "2              dress, fit, look, fabric, color, size, top, im, love, little   \n",
       "3               top, look, im, back, really, cute, love, small, fit, fabric   \n",
       "\n",
       "                                                                                   Representative Text  \n",
       "0  [living, casual, life, style, key, largo, fl, love, fitted, tshirt, instead, boxy, shape, im, ye...  \n",
       "1  [ordered, online, excited, unfortunately, didnt, work, maybe, style, issue, fit, maybe, im, long...  \n",
       "2  [found, jean, fitted, slouchy, reference, im, im, heavier, thru, hip, thigh, ordered, petite, us...  \n",
       "3  [love, print, design, photo, justice, fell, love, store, find, size, ordered, size, online, stil...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
